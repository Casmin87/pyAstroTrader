{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyAstroTrader\n",
    "\n",
    "# Create Model\n",
    "\n",
    "After downloading the quotes data for the asset selected with the ASSET_TO_CALCULATE environment variable, we need to add the astrological data to the quotes and then generate a XGBoost model\n",
    "\n",
    "First of all, we need to import the models that we need to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split as ttsplit\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from xgboost import plot_tree\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import eli5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```pyastrotrader``` is a python module that we created, in order to calculate astrological charts based on specific dates, and also to calculate aspects between charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyastrotrader import calculate_chart, calculate_aspects, calculate_transits, get_degrees, get_degree\n",
    "from pyastrotrader.utils import create_input_json\n",
    "from pyastrotrader.constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all settings and helper functions that we will use in the next cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings import *\n",
    "from helpers import *\n",
    "\n",
    "USING_CACHED_DATAFRAME = False\n",
    "CACHE_FILE = './output/{}.{}.cache'.format(ASSET_TO_CALCULATE, datetime.datetime.strftime(datetime.datetime.today(), '%Y%m%d') )\n",
    "CACHE_ASTRO_COLUMNS = './output/{}.{}.astro.cache'.format(ASSET_TO_CALCULATE, datetime.datetime.strftime(datetime.datetime.today(), '%Y%m%d') )\n",
    "\n",
    "if os.path.isfile(CACHE_FILE):\n",
    "    USING_CACHED_DATAFRAME = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the CSV file with the quotes downloaded, and also create a counter column to help in the calculated columns below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USING_CACHED_DATAFRAME:\n",
    "    StockPrices = pd.read_csv(\"{}.csv\".format(SOURCE_FILE))\n",
    "    StockPrices['Counter'] = np.arange(len(StockPrices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using several helper functions from ```helpers.py``` module, for each day we need to determine several indicators like:\n",
    "* The current trend\n",
    "* the future trend\n",
    "* If there was a change in the trend ( a swing trade opportunity )\n",
    "* current volatility for the previous days\n",
    "* and many other indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USING_CACHED_DATAFRAME:\n",
    "    max_counter = StockPrices['Counter'].max()\n",
    "\n",
    "    StockPricesDask = dd.from_pandas(StockPrices, npartitions=NPARTITIONS)\n",
    "    StockPrices['CorrectedDate'] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : correct_date(x), axis =1)).compute(scheduler='processes')\n",
    "    StockPrices['PreviousStartPrice'] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : get_previous_stock_price(StockPrices, x, SWING_TRADE_DURATION), axis =1), meta='float').compute(scheduler='processes')\n",
    "    StockPrices['FutureFinalPrice'] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : get_future_stock_price(StockPrices, x, max_counter, SWING_TRADE_DURATION), axis =1 ), meta='float').compute(scheduler='processes')\n",
    "    StockPrices['PreviousStartDate'] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : get_previous_stock_date(StockPrices, x, SWING_TRADE_DURATION), axis =1 ), meta='float').compute(scheduler='processes')\n",
    "    StockPrices['FutureFinalDate'] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : get_future_stock_date(StockPrices, x, max_counter, SWING_TRADE_DURATION), axis =1 ), meta='float').compute(scheduler='processes')\n",
    "\n",
    "    StockPricesDask = dd.from_pandas(StockPrices, npartitions=NPARTITIONS)\n",
    "    StockPrices['CurrentTrend'] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : calculate_current_trend(x), axis = 1), meta='float').compute(scheduler='processes')\n",
    "\n",
    "    StockPricesDask = dd.from_pandas(StockPrices, npartitions=NPARTITIONS)\n",
    "    StockPrices['FutureTrend'] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : calculate_future_trend(x), axis = 1), meta='float').compute(scheduler='processes')\n",
    "\n",
    "    StockPricesDask = dd.from_pandas(StockPrices, npartitions=NPARTITIONS)\n",
    "    StockPrices['SwingStrength'] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : calculate_swing_strenght(x), axis =1), meta='float').compute(scheduler='processes')\n",
    "    StockPrices['IntradayVolatility'] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : calculate_intraday_volatility(StockPrices, x, SWING_TRADE_DURATION), axis =1), meta='float').compute(scheduler='processes')\n",
    "\n",
    "    StockPrices['FutureTrendMax'] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : get_future_stock_max_price(StockPrices, x, max_counter, SWING_TRADE_DURATION), axis = 1), meta='float').compute(scheduler='processes')\n",
    "    StockPrices['FutureTrendMin'] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : get_future_stock_min_price(StockPrices, x, max_counter, SWING_TRADE_DURATION), axis = 1), meta='float').compute(scheduler='processes')\n",
    "\n",
    "    StockPricesDask = dd.from_pandas(StockPrices, npartitions=NPARTITIONS)\n",
    "    StockPrices['IsSwing'] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : detect_swing_trade(x, SWING_EXPECTED_VOLATILITY), axis =1), meta='float').compute(scheduler='processes')\n",
    "    StockPricesDask = dd.from_pandas(StockPrices, npartitions=NPARTITIONS)\n",
    "    StockPrices['IsSwing'] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : clean_swing_trade(StockPrices, x, SWING_EXPECTED_VOLATILITY), axis =1), meta='float').compute(scheduler='processes')\n",
    "\n",
    "    StockPricesDask = dd.from_pandas(StockPrices, npartitions=NPARTITIONS)\n",
    "    StockPrices['StockIncreasedPrice'] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : detect_price_increase(x, STAGNATION_THRESHOLD), axis =1), meta='float').compute(scheduler='processes')\n",
    "    StockPrices['StockDecreasedPrice'] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : detect_price_decrease(x, STAGNATION_THRESHOLD), axis =1), meta='float').compute(scheduler='processes')\n",
    "    StockPrices['StockStagnated'] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : detect_price_stagnated(x, STAGNATION_THRESHOLD), axis =1), meta='float').compute(scheduler='processes')\n",
    "    StockPrices['StockPriceChange'] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : calculate_price_change(StockPrices, x), axis =1), meta='float').compute(scheduler='processes')\n",
    "\n",
    "    StockPrices['TARGET_IS_SWING'] = StockPrices['IsSwing']\n",
    "    StockPrices['TARGET_PRICE_INCREASE'] = StockPrices['StockIncreasedPrice']\n",
    "    StockPrices['TARGET_PRICE_DECREASE'] = StockPrices['StockDecreasedPrice']\n",
    "    StockPrices['TARGET_PRICE_STAGNATION'] = StockPrices['StockStagnated']\n",
    "    StockPrices['TARGET_PRICE_CHANGE'] = StockPrices['StockPriceChange']                                                                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all the analisys, we can generate a excel file in order to help debug the indicators generated above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USING_CACHED_DATAFRAME:\n",
    "    output_excel_file='./output/{}.Analisys.xlsx'.format(ASSET_TO_CALCULATE)\n",
    "    StockPrices.to_excel(output_excel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To debug the indicators, we can plot a stock chart with the swing indication, but this is commented out as it requires a lot of computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "swing_to_chart = []\n",
    "for index, current_swing in StockPrices[StockPrices['IsSwing'] == 1].iterrows():\n",
    "    swing_to_chart.append(dict(\n",
    "        x0=current_swing['CorrectedDate'], \n",
    "        x1=current_swing['CorrectedDate'], \n",
    "        y0=0, \n",
    "        y1=1, \n",
    "        xref='x', \n",
    "        yref='paper',\n",
    "        line_width=2))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fig = go.Figure(data=[go.Candlestick(\n",
    "                x=StockPrices['CorrectedDate'],\n",
    "                open=StockPrices['Open'],\n",
    "                high=StockPrices['High'],\n",
    "                low=StockPrices['Low'],\n",
    "                close=StockPrices['Price'])])\n",
    "fig.update_layout(\n",
    "    title=\"{} Detected Swing Trade Opportunities\".format(ASSET_TO_CALCULATE),\n",
    "    width=1000,\n",
    "    height=500,\n",
    "    xaxis_rangeslider_visible=False,\n",
    "    shapes=swing_to_chart,\n",
    "    margin=go.layout.Margin(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=30,\n",
    "        pad=4\n",
    "    ),    \n",
    ")\n",
    "#fig.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, in order to calculate the astrological indicators for the current ASSET_TO_CALCULATE, we need to generate a natal chart of the asset, which traditionally is the first trade date on the current exchange "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USING_CACHED_DATAFRAME:\n",
    "    asset_natal_chart_input = create_input_json(NATAL_DATE, \n",
    "                                            DEFAULT_PARAMETERS, \n",
    "                                            DEFAULT_CONFIG)\n",
    "\n",
    "    asset_natal_chart = calculate_chart(asset_natal_chart_input)\n",
    "    dates_to_generate = list(StockPrices['CorrectedDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for all the dates on the pandas dataframe containing the quotes, we need to generate astrological charts with the list of planets to consider: ```PLANETS_TO_CALCULATE```, their aspects: ```ASPECTS_TO_CALCULATE```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USING_CACHED_DATAFRAME:\n",
    "    def generate_charts(current_date):\n",
    "        chart_input = create_input_json(current_date + 'T10:00:00-03:00', \n",
    "                                          DEFAULT_PARAMETERS, \n",
    "                                          DEFAULT_CONFIG)\n",
    "        current_chart = calculate_chart(chart_input)\n",
    "        return (current_date,\n",
    "                current_chart, \n",
    "                calculate_transits(asset_natal_chart, current_chart, PLANETS_TO_CALCULATE, ASPECTS_TO_CALCULATE, 4),\n",
    "                calculate_aspects(current_chart, PLANETS_TO_CALCULATE, ASPECTS_TO_CALCULATE, 4))\n",
    "\n",
    "    with mp.Pool(processes = NPARTITIONS) as p:\n",
    "        results = p.map(generate_charts, dates_to_generate)\n",
    "\n",
    "    for x in results:\n",
    "        charts[x[0]] = x[1]\n",
    "        aspects[x[0]] = x[2]\n",
    "        aspects_transiting[x[0]] = x[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the natal chart and also all the charts for each date in the pandas dataframe, now we need to add to the pandas dataframe, the astrological aspects that occur in each date, we will set only to 1 if there is a aspect occuring or 0 if not, we also will check for aspects on the transiting chart as well as aspects between the natal chart and the transiting chart\n",
    "\n",
    "**astro_columns** will indicate the name of the columns containing astrological indicators in the pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USING_CACHED_DATAFRAME:\n",
    "    astro_columns = []\n",
    "\n",
    "    for current_planet in PLANETS_TO_CALCULATE:\n",
    "        column_name=\"ASTRO_{}_POSITION\".format(PLANETS[current_planet]).upper()\n",
    "        StockPricesDask = dd.from_pandas(StockPrices, npartitions=NPARTITIONS)\n",
    "        StockPrices[column_name] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : int(get_degree_for_planet(x, current_planet)), axis =1), meta='int').compute(scheduler='processes')\n",
    "        StockPrices[column_name] = pd.to_numeric(StockPrices[column_name],  downcast='float', errors='coerce')   \n",
    "        astro_columns.append(column_name)   \n",
    "        for second_planet in PLANETS_TO_CALCULATE:\n",
    "            if current_planet == second_planet:\n",
    "                continue\n",
    "            column_name=\"ASTRO_{}_{}_DIFF\".format(PLANETS[current_planet], PLANETS[second_planet]).upper()\n",
    "            StockPricesDask = dd.from_pandas(StockPrices, npartitions=NPARTITIONS)\n",
    "            StockPrices[column_name] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : abs(int(get_degree_for_planet(x, current_planet) - get_degree_for_planet(x, second_planet))), axis =1), meta='int').compute(scheduler='processes')\n",
    "            StockPrices[column_name] = pd.to_numeric(StockPrices[column_name],  downcast='float', errors='coerce')   \n",
    "            astro_columns.append(column_name)   \n",
    "        \n",
    "\n",
    "    for first_planet in PLANETS_TO_CALCULATE:\n",
    "        for second_planet in PLANETS_TO_CALCULATE:\n",
    "            for aspect in ASPECTS_TO_CALCULATE:\n",
    "                column_name=\"ASTRO_{}_{}_{}\".format(PLANETS[first_planet],ASPECT_NAME[aspect],PLANETS[second_planet]).upper()\n",
    "                aspect_column_name = column_name\n",
    "                astro_columns.append(column_name)\n",
    "                StockPricesDask = dd.from_pandas(StockPrices, npartitions=NPARTITIONS)\n",
    "                StockPrices[column_name] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : is_aspected(x, first_planet, second_planet, aspect), axis =1), meta='float').compute(scheduler='processes')\n",
    "                StockPrices[column_name] = pd.to_numeric(StockPrices[column_name],  downcast='float', errors='coerce')\n",
    "\n",
    "                StockPricesDask = dd.from_pandas(StockPrices, npartitions=NPARTITIONS)\n",
    "                column_name=\"ASTRO_TRANSITING_{}_{}_{}\".format(PLANETS[first_planet],ASPECT_NAME[aspect],PLANETS[second_planet]).upper()\n",
    "                astro_columns.append(column_name)\n",
    "                StockPrices[column_name] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : is_aspected_transiting(x, first_planet, second_planet, aspect), axis =1), meta='float').compute(scheduler='processes')\n",
    "                StockPrices[column_name] = pd.to_numeric(StockPrices[column_name],  downcast='float', errors='coerce')                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need also to determine which planets are retrograde in each date of the pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USING_CACHED_DATAFRAME:\n",
    "    for first_planet in []:\n",
    "        column_name=\"ASTRO_{}_RETROGADE\".format(PLANETS[first_planet]).upper()\n",
    "        astro_columns.append(column_name)\n",
    "        StockPricesDask = dd.from_pandas(StockPrices, npartitions=NPARTITIONS)\n",
    "        StockPrices[column_name] = StockPricesDask.map_partitions(lambda df : df.apply(lambda x : is_retrograde(x, first_planet), axis =1), meta='float').compute(scheduler='processes')\n",
    "        StockPrices[column_name] = pd.to_numeric(StockPrices[column_name],  downcast='float',errors='coerce')\n",
    "        \n",
    "if USING_CACHED_DATAFRAME:        \n",
    "    StockPrices = pd.read_pickle(CACHE_FILE)\n",
    "    with open(CACHE_ASTRO_COLUMNS, 'rb') as f:\n",
    "        astro_columns = pickle.load(f)    \n",
    "else:\n",
    "    StockPrices.to_pickle(CACHE_FILE)\n",
    "    with open(CACHE_ASTRO_COLUMNS, 'wb') as f:\n",
    "        pickle.dump(astro_columns, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the pandas dataframe has been populated with the astrological indicators, we can now train the XGBoost models in order to predict the following target variables:\n",
    "* Price Increase: There is a increase in price after that date\n",
    "* Price Decrease: There is a decrease in price after that date\n",
    "* Price Stagnation: There is a stagnation in price after that date\n",
    "* Swing Trade: There is a change in trend after that date\n",
    "    \n",
    "**Important to notice that we will use as input only the astro_columns columns which contains astrological indicators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster_price_change, score_price_change = get_best_booster('TARGET_PRICE_CHANGE', MAX_INTERACTIONS, StockPrices, astro_columns)\n",
    "print(\"Best Score for Price Change Model:{}\".format(score_price_change))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save each model score in a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_price_change_file_name = './output/{}.score.price.change.txt'.format(ASSET_TO_CALCULATE)\n",
    "\n",
    "with open(score_price_change_file_name, 'w') as f:\n",
    "    f.write(\"{}:{}\".format(ASSET_TO_CALCULATE,str(score_price_change)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate for each model the relevant astrological variables, used in each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_features_price_change = sorted( ((v,k) for k,v in booster_price_change.get_score().items()), reverse=True)\n",
    "\n",
    "display(relevant_features_price_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now write such features to text files in order to improve the analisys of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_features(f, list_to_write):\n",
    "    for item_to_write in list_to_write:\n",
    "        f.write('{}-{}'.format(ASSET_TO_CALCULATE,str(item_to_write).replace(')','').replace('(','').replace('\\'','').replace(' ','') + '\\n'))\n",
    "        \n",
    "features_price_change_file_name = './output/{}.features.price.change.txt'.format(ASSET_TO_CALCULATE)\n",
    "\n",
    "with open(features_price_change_file_name, 'w') as f:\n",
    "    write_features(f,relevant_features_price_change)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the predicted value for each model on the pandas dataframe, creating a column for it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StockPrices['PredictPriceChange'] = StockPrices.apply(lambda x:predict_score(x, booster_price_change, StockPrices, astro_columns), axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save the model for further use on the ```Predict.ipynb``` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster_price_change.save_model('./output/{}_price_change.model'.format(ASSET_TO_CALCULATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save a excel with all the data produced..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_excel_file='./output/{}.Analisys.xlsx'.format(ASSET_TO_CALCULATE)\n",
    "StockPrices.to_excel(output_excel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plotting of charts has been commented out as it is very resource consuming..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "swing_to_chart = []\n",
    "for index, current_swing in StockPrices[StockPrices['PredictSwingTradeScore'] > 0.9].iterrows():\n",
    "    swing_to_chart.append(dict(\n",
    "        x0=current_swing['CorrectedDate'], \n",
    "        x1=current_swing['CorrectedDate'], \n",
    "        y0=0, \n",
    "        y1=1, \n",
    "        xref='x', \n",
    "        yref='paper',\n",
    "        line_width=2))\n",
    "\"\"\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fig = go.Figure(data=[go.Candlestick(\n",
    "                x=StockPrices['CorrectedDate'],\n",
    "                open=StockPrices['Open'],\n",
    "                high=StockPrices['High'],\n",
    "                low=StockPrices['Low'],\n",
    "                close=StockPrices['Price'])])\n",
    "fig.update_layout(\n",
    "    title=\"{} Swing Trade Opportunities detected by XGBoost\".format(ASSET_TO_CALCULATE),\n",
    "    width=1000,\n",
    "    height=500,\n",
    "    xaxis_rangeslider_visible=False,\n",
    "    shapes=swing_to_chart,\n",
    "    margin=go.layout.Margin(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=30,\n",
    "        pad=4\n",
    "    ),    \n",
    ")\n",
    "#fig.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "swing_to_chart = []\n",
    "for index, current_swing in StockPrices[StockPrices['PredictPriceIncreaseScore'] > 5].iterrows():\n",
    "    swing_to_chart.append(dict(\n",
    "        x0=current_swing['CorrectedDate'], \n",
    "        x1=current_swing['CorrectedDate'], \n",
    "        y0=0, \n",
    "        y1=1, \n",
    "        xref='x', \n",
    "        yref='paper',\n",
    "        line_width=2))\n",
    "\"\"\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fig = go.Figure(data=[go.Candlestick(\n",
    "                x=StockPrices['CorrectedDate'],\n",
    "                open=StockPrices['Open'],\n",
    "                high=StockPrices['High'],\n",
    "                low=StockPrices['Low'],\n",
    "                close=StockPrices['Price'])])\n",
    "fig.update_layout(\n",
    "    title=\"{} Price Increase Opportunities detected by XGBoost (Min {}%)\".format(ASSET_TO_CALCULATE, STAGNATION_THRESHOLD),\n",
    "    width=1000,\n",
    "    height=500,\n",
    "    xaxis_rangeslider_visible=False,\n",
    "    shapes=swing_to_chart,\n",
    "    margin=go.layout.Margin(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=30,\n",
    "        pad=4\n",
    "    ),    \n",
    ")\n",
    "#fig.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
